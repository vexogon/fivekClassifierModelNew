{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "Multiclass classification for only setting after multi-label models were not performing well, so we will try multiclass classification for setting only.",
   "id": "33c28b4a285b357d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#https://pypi.org/project/rawpy/",
   "id": "de0ff2d43f88a01f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pandas import DataFrame\n",
    "from torch import nn\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import rawpy\n",
    "import os"
   ],
   "id": "9102ac85fee32ff6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #Numpy and Pandas FutureWarnings - ignore them for now, we can fix them later"
   ],
   "id": "5fe83698f9f36bcb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv('categories.csv')\n",
    "df.head()"
   ],
   "id": "32ec50fb35b21b01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = df.drop(columns=['location','time_of_day','skyCondition']) # Drop other columns, we will use 'setting' as the target variable, input will be the image.",
   "id": "5c0246ba26df9fa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.get_dummies(df, columns=['setting'], dtype='int')\n",
    "df.columns"
   ],
   "id": "e6588d463b667783"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()",
   "id": "f110d23a0295ed37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "device = torch.device(\"mps\")",
   "id": "a5caf714b9f0e9d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Rewrite the dataset class\n",
    "class MainDataset(Dataset):\n",
    "    def __init__(self, data,image_dir, transform=None):\n",
    "        self.data = data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.bounds = []\n",
    "\n",
    "        if not os.path.exists(self.image_dir):\n",
    "            raise ValueError(f\"Image directory {self.image_dir} does not exist.\")\n",
    "\n",
    "        for file in os.listdir(self.image_dir):\n",
    "            if not file.startswith('HQa'):\n",
    "                continue\n",
    "\n",
    "            start = int(file.split('HQa')[1].split('to')[0])\n",
    "            end = int(file.split('to')[1])\n",
    "            self.bounds.append((file,start, end))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def dng_to_numpy(self, path):\n",
    "        with rawpy.imread(path) as img:\n",
    "            return img.postprocess(use_camera_wb=True, no_auto_bright=True) #Trying to get the original image data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        img_name = row['img_name']\n",
    "        img_number = int(img_name.split('a')[1].split('-')[0])  # Extract the number from the image name\n",
    "\n",
    "        for file,start,end in self.bounds:\n",
    "            if not start <= img_number <= end:\n",
    "                continue\n",
    "\n",
    "            path = f'{self.image_dir}/{file}/photos/{img_name}.dng'\n",
    "            if not os.path.exists(path):\n",
    "                raise ValueError(f\"Image file {path} does not exist.\")\n",
    "\n",
    "            image = self.dng_to_numpy(path)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            label = self.data.iloc[idx, 1:].values.tolist() #idx is row, 1: is all columns except the first one (img_name), which are the labels\n",
    "            label = torch.tensor(label, dtype=torch.float32)  # Convert to tensor\n",
    "\n",
    "            return image, label\n",
    "\n",
    "        raise IndexError(f\"Image with index {idx} not found in the dataset.\")"
   ],
   "id": "f32383b53f45865b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset = MainDataset(data=df, image_dir='raw_photos', transform=transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for pre-trained models\n",
    "]))"
   ],
   "id": "ee7feb3339d96133"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_size = int(0.2 * len(dataset))  # 20% for validation\n",
    "test_size = int(0.2 * len(dataset))  # 20% for testing\n",
    "train_size = len(dataset) - val_size - test_size  # Remaining for training\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ],
   "id": "d96f2e29a6cedb9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Add data augmentation depending on overfitting",
   "id": "3b150e850fb2e7f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#For now lets use the same transforms for all datasets, we can change if we are overfitting (e.g. by using data augmentation)\n",
    "#train_dataset.dataset.transform ="
   ],
   "id": "637e23e395920c57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "id": "fdaf298355918112"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_images, train_labels = next(iter(train_loader))\n",
    "print(train_images.shape, train_labels.shape)"
   ],
   "id": "ffbbfc1328e271b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torchvision.utils import make_grid\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "print(train_images.dtype)  # Check the shape of the images tensor\n",
    "print(train_labels.dtype)  # Check the shape of the labels tensor\n",
    "\n",
    "imshow(make_grid(train_images))"
   ],
   "id": "1be85bd5d10fbc3f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look at flosst code for data augmentation and transforms",
   "id": "fd6f5ee73f222b4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#n_samples / (n_classes * np.bincount(y))\n",
    "\n",
    "#Build my own class weight function\n",
    "\n",
    "def class_weights(data: DataFrame):\n",
    "    weights = []\n",
    "    for col in data.columns[1:]:  # Skip the first column (img_name)\n",
    "        classes = data[col].unique()\n",
    "        total_samples = len(data[col])\n",
    "        class_weight = total_samples / (len(classes) * data[col].value_counts())\n",
    "        weights.append(class_weight[1]) # Assuming the positive class is the second one (1)\n",
    "    class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "    return class_weights"
   ],
   "id": "6fdeb68738f1c1fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "weights = class_weights(df)\n",
    "print(weights)"
   ],
   "id": "e66a95a72e8fe394"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Applyimg multiclass classification loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=weights).to(device) #Contains softmax and negative log likelihood loss"
   ],
   "id": "12f3b5f581e25efe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look at notes from paper about suggested depth and width of the model https://arxiv.org/pdf/1512.03385",
   "id": "8b2b17ccfd508a56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.avg_pool = nn.AvgPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=1, padding=3) #Padding should help keep the spatial dimensions the same for longer giving us more features to work with later\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        #max pool 248\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, stride=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        #max pool 120\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.avg_global_pool = nn.AdaptiveAvgPool2d(1)  # Global average pooling - this will reduce the spatial dimensions to 1x1, allowing us to flatten the output and classify it instead of using a fully connected layer. Basically turns the feature map into a single vector per channel.\n",
    "        #It does this by averaging the values in each channel across the spatial dimensions, resulting in a tensor of shape (batch_size, num_channels, 1, 1).\n",
    "\n",
    "        #Due to average pooling size is only 256\n",
    "        self.fc1 = nn.Linear(256, len(df.columns) - 1) #Classification layer (new)\n",
    "        # self.fc1 = nn.Linear(256 * 114 * 114, out_features=len(df.columns) - 1) #Classification layer\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x) #Break the linearity of the model, so it can learn more complex functions\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "        x = self.dropout(x)  # Dropout after the first two convolutional layers\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "        #495\n",
    "\n",
    "        x = self.max_pool(x)\n",
    "        #248\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "        #245\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "        x = self.dropout(x)  # Dropout after the next two convolutional layers\n",
    "\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "\n",
    "        x = self.max_pool(x) # Max pooling after the next three convolutional layers\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "        x = self.dropout(x)  # Dropout after the next two convolutional layers\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.bn8(x)\n",
    "        x = nn.functional.relu(x)  # Apply ReLU activation function, breaks the linearity of the model, so it can learn more complex functions\n",
    "\n",
    "        x = self.avg_global_pool(x)  # Global average pooling for classification, basically turn the feature map into a single vector per channel (saves you doing a fully connected layer)\n",
    "        x = torch.flatten(x, 1)  # Flatten the output for the fully connected layer\n",
    "        x = self.fc1(x)  # Classification layer\n",
    "        return x\n",
    "\n",
    "    def train_epoch(self, train_loader, loss_values, epoch):\n",
    "        running_loss = 0.0\n",
    "        total_train_data = len(train_loader)\n",
    "        for i, data in enumerate(train_loader):# Start counting from 0, enumerate give us a counter as well as the data\n",
    "            # Every data instance is an input + label pair\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device) # Move inputs and labels to the same device as the model (apple silicon chip, cuda, or cpu)\n",
    "\n",
    "            optimizer.zero_grad() # Zero your gradients for every batch!\n",
    "\n",
    "            outputs = self(inputs) # Make predictions for this batch (forward pass)\n",
    "\n",
    "            loss = criterion(outputs, labels) # Compute the loss and its gradients\n",
    "            loss.backward()  # Backward pass\n",
    "\n",
    "            optimizer.step() # Adjust learning weights\n",
    "            running_loss += loss.item() # running_loss is the total loss for the epoch, we will average it later\n",
    "\n",
    "        avg_loss = running_loss / total_train_data # Average loss for the epoch (over the all batches in the training set, given by len(train_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")  # Print the average loss for this epoch\n",
    "        loss_values.append(avg_loss) #log the average loss for the epoch to the loss_values list\n",
    "        return avg_loss, loss_values\n",
    "\n",
    "    #Maybe add train function (train_epoch) in here, makes a bit cleaner?"
   ],
   "id": "1b780f83b3be4c41"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Look at flosst code and docs for the rest of the code (training loop etc)",
   "id": "4d2d34d670a89f7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "optimizer = torch.optim.AdamW(Model().parameters(), lr=1e-3)  # Using adamW optimizer with weight decay, which is good for regularization, standard L2 regularization is 0.01",
   "id": "bcba604e0f6ce68c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "recent_train_losses = []  # List to keep track of recent training losses for early stopping\n",
    "previous_train_losses = []\n",
    "\n",
    "#This was broken - made a change idk now\n",
    "def early_stopping(avg_loss,patience=5):\n",
    "\n",
    "    if len(recent_train_losses) < patience:\n",
    "        recent_train_losses.append(avg_loss)  # Add the current average loss to the recent losses\n",
    "\n",
    "    if len(previous_train_losses) < patience:\n",
    "        previous_train_losses.append(recent_train_losses[0])\n",
    "        recent_train_losses.pop(0)\n",
    "\n",
    "    if len(recent_train_losses) == patience and len(previous_train_losses) == patience:\n",
    "        avg_of_previous_losses = np.mean(previous_train_losses)\n",
    "        avg_of_recent_previous_losses = np.mean(recent_train_losses)\n",
    "        if avg_of_previous_losses < avg_of_recent_previous_losses:\n",
    "            print(f\"Early stopping condition met: {avg_of_previous_losses} < {avg_of_recent_previous_losses}\")\n",
    "            return True, recent_train_losses, previous_train_losses  # Early stopping condition met\n",
    "\n",
    "        print(f\"Early stopping condition not met: {avg_of_previous_losses} >= {avg_of_recent_previous_losses}\")\n",
    "        previous_train_losses.append(recent_train_losses[0])  #Add oldest recent loss to previous losses\n",
    "        recent_train_losses.pop(0)  # Remove the oldest loss to maintain the size of the list\n",
    "\n",
    "    return False, recent_train_losses, previous_train_losses  # No early stopping condition met\n"
   ],
   "id": "8ae986d0d5172ab8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = Model().to(device)  # Initialize the model and move it to the device (GPU or CPU)",
   "id": "832efc128e5deeed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#There's a bunch of tensorboard stuff in the pytorch tutorial, we don't need it for now, but we can add it later if we want to visualize the training process\n",
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/classifier_trainer{}'.format(timestamp))\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "best_vloss = 1_000_000. #Super big number to start with, so we can save the model if the validation loss is lower than this\n",
    "\n",
    "# Initialize lists to keep track of loss values for plotting later\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "\n",
    "\n",
    "total_val_data = len(val_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1)) # Start counting epochs from 1 for better readability\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data, so we are not in evaluation mode.\n",
    "    model.train(True)\n",
    "\n",
    "    #Actually train the model, this is where the training happens\n",
    "    #Keep track of loss values for plotting later, keep giving the loss_values array to the train_one_epoch function so that it keeps track of the loss values\n",
    "    avg_loss, loss_values = model.train_epoch(train_loader, loss_values,epoch)\n",
    "\n",
    "    early_stop,recent_train_losses, previous_train_losses = early_stopping(avg_loss,patience=5)  # Check if early stopping condition is met\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    #This is the validation loop, it will run after each epoch and compute the validation loss\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader, 0): #Computes the validation loss per epoch\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device).float()  # Move inputs and labels to the same device as the model\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = criterion(voutputs, vlabels)\n",
    "            #running vloss is the total validation loss for the epoch, we will average it later\n",
    "            running_vloss += vloss.item()  # Add the validation loss for this batch to the running validation loss\n",
    "\n",
    "    # Average validation loss for the epoch (over the all batches in the validation set, given by len(val_loader))\n",
    "    avg_vloss = running_vloss / total_val_data\n",
    "    val_loss_values.append(avg_vloss)\n",
    "\n",
    "    #Gives the loss and validation loss for the epoch into the terminal\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # for both training and validation w]e log the average loss for the epoch\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                       { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                       epoch + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    #Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss: #If the validation loss is lower than the best validation loss so far, save the model\n",
    "\n",
    "        #Best vloss starts at a super high number, so the first model will always be saved\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch + 1) # Save the model with a timestamp and epoch number (epoch + 1 to start from 1)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if early_stop:  # Check if early stopping condition is met\n",
    "        print(\"Early stopping triggered, stopping training.\")\n",
    "        break  # Stop training if early stopping condition is met\n",
    "\n",
    "    #Onto the next epoch, which will also run through all the batches in the training set and validation set and give the average los s for the epoch"
   ],
   "id": "bebaae3895242c9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finish metrics and i need google collab",
   "id": "558f00c53cf15a38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Plot the training and validation loss\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.plot(val_loss_values, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()"
   ],
   "id": "a7c4e4d2336572e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Training set evaluation\n",
    "from torcheval.metrics import MulticlassAccuracy #This lib has so many of these - good to use i think\n",
    "model.eval() #Turns off dropout layers\n",
    "metric = MulticlassAccuracy()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)  # Get the predicted class indices\n",
    "        metric.update(preds, labels)  # Update the metric with predictions and true labels\n",
    "\n",
    "accuracy = metric.compute()  # Compute the accuracy\n",
    "print(f'Training set accuracy: {accuracy:.4f}')  # Print the accuracy"
   ],
   "id": "d31d8fc65130f93b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#Test set evaluation\n",
    "model.eval()\n",
    "metric = MulticlassAccuracy()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=1)  # Get the predicted class indices\n",
    "        metric.update(preds, labels)  # Update the metric with predictions and true labels\n",
    "\n",
    "accuracy = metric.compute()  # Compute the accuracy\n",
    "print(f'Test set accuracy: {accuracy:.4f}')  # Print the accuracy"
   ],
   "id": "3fdf36e60425dcbf"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
